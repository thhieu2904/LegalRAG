#!/usr/bin/env python3
"""
TEST: Official PhoGPT Format - S·ª≠ d·ª•ng template ch√≠nh th·ª©c
"""

import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

from app.services.language_model import LLMService

def test_official_format():
    """Test official PhoGPT format - ### C√¢u h·ªèi: ### Tr·∫£ l·ªùi:"""
    
    print("=== TEST OFFICIAL PHOGPT FORMAT ===")
    
    # Initialize service
    llm_service = LLMService()
    
    # Test query
    query = "Th·ªß t·ª•c ƒëƒÉng k√Ω k·∫øt h√¥n c√≥ t√≠nh ph√≠ kh√¥ng?"
    context = "Th√¥ng tin ƒëƒÉng k√Ω k·∫øt h√¥n mi·ªÖn ph√≠."
    
    print(f"üîç Query: {query}")
    print(f"üìÑ Context: {context}")
    
    try:
        # Generate response
        result = llm_service.generate_response(
            user_query=query,
            context=context
        )
        
        print(f"\n‚úÖ Success!")
        print(f"üìù Response: '{result['response']}'")
        print(f"üìä Response length: {len(result['response'])} chars")
        print(f"‚è±Ô∏è Processing time: {result['processing_time']:.2f}s")
        print(f"üßÆ Tokens - Prompt: {result['prompt_tokens']}, Completion: {result['completion_tokens']}")
        
        # Check if response is meaningful
        response_lower = result['response'].lower()
        if (len(result['response']) > 20 and 
            ("mi·ªÖn ph√≠" in response_lower or "kh√¥ng" in response_lower or "free" in response_lower)):
            print("‚úÖ RESPONSE LOOKS GREAT! Using official format worked!")
        else:
            print("‚ö†Ô∏è Response could be improved")
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_official_format()
