"""
Debug script ƒë·ªÉ ki·ªÉm tra LLM output v√† system prompt
S·∫Ω test v·ªõi c√°c query ƒë√£ b·ªã l·ªói ƒë·ªÉ t√¨m nguy√™n nh√¢n
"""

import os
import sys
import logging
from pathlib import Path

# Add backend path
backend_path = Path(__file__).parent
sys.path.append(str(backend_path))

from app.services.rag_engine import OptimizedEnhancedRAGService
from app.services.vector_database import VectorDBService
from app.services.language_model import LLMService
from app.core.config import settings

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def debug_llm_response():
    """Debug LLM response v·ªõi c√°c test cases ƒë√£ b·ªã l·ªói"""
    
    print("üîç DEBUGGING LLM HALLUCINATION ISSUES")
    print("=" * 60)
    
    # Initialize services
    print("üöÄ Initializing services...")
    vectordb_service = VectorDBService()
    llm_service = LLMService()
    
    # Initialize RAG service v·ªõi dependencies
    rag_service = OptimizedEnhancedRAGService(
        documents_dir=str(settings.documents_dir),
        vectordb_service=vectordb_service,
        llm_service=llm_service
    )
    
    # Test cases ƒë√£ b·ªã l·ªói
    test_cases = [
        {
            "query": "mu·ªën h·ªèi v·ªÅ th·ªß t·ª•c nh·∫≠n nu√¥i con √°",
            "expected": "Th√¥ng tin chi ti·∫øt v·ªÅ th·ªß t·ª•c nh·∫≠n nu√¥i con",
            "issue": "LLM h·ªèi l·∫°i thay v√¨ tr·∫£ l·ªùi tr·ª±c ti·∫øp"
        },
        {
            "query": "ƒëƒÉng k√Ω khai sinh cho con c·∫ßn gi·∫•y t·ªù g√¨ v·∫≠y",
            "expected": "Danh s√°ch gi·∫•y t·ªù c·∫ßn thi·∫øt cho tr∆∞·ªùng h·ª£p th√¥ng th∆∞·ªùng",
            "issue": "LLM tr·∫£ l·ªùi r·ªëi r·∫Øm, tr·ªôn l·∫´n nhi·ªÅu tr∆∞·ªùng h·ª£p"
        },
        {
            "query": "mu·ªën ƒëƒÉng k√Ω khai sinh th√¨ c√≥ c·∫ßn ƒë√≥ng ti·ªÅn kh√¥ng",
            "expected": "Th√¥ng tin v·ªÅ l·ªá ph√≠ ƒëƒÉng k√Ω khai sinh", 
            "issue": "LLM tr·∫£ l·ªùi ho√†n to√†n sai ch·ªß ƒë·ªÅ (v·ªÅ x√°c ƒë·ªãnh cha con)"
        },
        {
            "query": "m√¨nh mu·ªën h·ªèi ph√≠ khi m√† ƒëƒÉng k√Ω khai sinh √°",
            "expected": "Th√¥ng tin v·ªÅ ph√≠ ƒëƒÉng k√Ω khai sinh",
            "issue": "Router sai + LLM t√≥m t·∫Øt sai"
        }
    ]
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüìù TEST CASE {i}: {test_case['query']}")
        print(f"üéØ Expected: {test_case['expected']}")
        print(f"‚ö†Ô∏è  Issue: {test_case['issue']}")
        print("-" * 50)
        
        try:
            # Get response t·ª´ RAG
            result = rag_service.enhanced_query(
                query=test_case['query'],
                session_id=f"debug_session_{i}"
            )
            
            if result.get('type') == 'answer':
                print(f"ü§ñ LLM Response:")
                print(f"   {result['answer'][:200]}...")
                print()
                
                # Check context info
                context_info = result.get('context_info', {})
                print(f"üìö Context Info:")
                print(f"   - Nucleus chunks: {context_info.get('nucleus_chunks', 0)}")
                print(f"   - Context length: {context_info.get('context_length', 0)}")
                print(f"   - Source docs: {context_info.get('source_documents', [])}")
                
                # Check routing info
                routing_info = result.get('routing_info', {})
                print(f"üéØ Routing Info:")
                print(f"   - Best collections: {routing_info.get('best_collections', [])}")
                
                # KI·ªÇM TRA CONTEXT C·ª§ TH·ªÇ - ƒê√ÇY L√Ä PH·∫¶N QUAN TR·ªåNG NH·∫§T
                session = rag_service.get_session(f"debug_session_{i}")
                if session and session.query_history:
                    last_query = session.query_history[-1]
                    if 'debug_context' in last_query:
                        print(f"\nüìã RAW CONTEXT SENT TO LLM:")
                        context_preview = last_query['debug_context'][:500] + "..." if len(last_query['debug_context']) > 500 else last_query['debug_context']
                        print(context_preview)
            else:
                print(f"‚ùå Error: {result.get('error', 'Unknown error')}")
                
        except Exception as e:
            print(f"‚ùå Exception: {e}")
        
        print("\n" + "=" * 60)
        
        # Wait for user input ƒë·ªÉ xem k·∫øt qu·∫£
        input("Press Enter ƒë·ªÉ ti·∫øp t·ª•c test case ti·∫øp theo...")

if __name__ == "__main__":
    debug_llm_response()
