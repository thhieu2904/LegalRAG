#!/usr/bin/env python3
"""
ğŸ§ª COMPREHENSIVE TESTING SUITE

Final validation Ä‘á»ƒ ensure migration success:
âœ… Test file structure integrity  
âœ… Test backend API integration
âœ… Test FilterEngine business logic
âœ… Validate performance improvements
âœ… Confirm storage reduction
"""

import json
import os
import glob
import time
from pathlib import Path

def test_storage_reduction():
    """Measure actual storage reduction achieved"""
    
    print("ğŸ“Š STORAGE REDUCTION ANALYSIS")
    print("=" * 40)
    
    # Measure current questions.json size
    questions_files = glob.glob("data/**/*questions.json", recursive=True)
    total_questions_size = sum(os.path.getsize(f) for f in questions_files)
    
    # Measure backup router_questions.json size
    backup_files = glob.glob("migration_backup_*/**/*router_questions.json", recursive=True)
    total_backup_size = sum(os.path.getsize(f) for f in backup_files)
    
    if total_backup_size > 0:
        reduction = ((total_backup_size - total_questions_size) / total_backup_size) * 100
        print(f"ğŸ“ Original size: {total_backup_size:,} bytes")
        print(f"ğŸ“ New size: {total_questions_size:,} bytes")
        print(f"ğŸ“‰ Reduction: {reduction:.1f}%")
        print(f"ğŸ’¾ Space saved: {total_backup_size - total_questions_size:,} bytes")
    else:
        print("âš ï¸  Backup files not found for comparison")
    
    return {
        "questions_files": len(questions_files),
        "total_questions_size": total_questions_size,
        "total_backup_size": total_backup_size,
        "reduction_percent": reduction if total_backup_size > 0 else 0
    }

def test_filter_engine():
    """Test FilterEngine business logic"""
    
    print("\nğŸ”§ FILTER ENGINE TEST")
    print("=" * 40)
    
    # Sample metadata Ä‘á»ƒ test
    sample_metadata = {
        "title": "ÄÄƒng kÃ½ khai sinh",
        "code": "QT 01/CX-HCTP",
        "executing_agency": "á»¦y ban nhÃ¢n dÃ¢n cáº¥p xÃ£",
        "fee_vnd": 0,
        "processing_time": "3 ngÃ y"
    }
    
    try:
        # Import FilterEngine
        import sys
        sys.path.append("app/services")
        from filter_engine import FilterEngine
        
        # Test filter derivation
        filters = FilterEngine.derive_smart_filters(sample_metadata)
        
        print(f"ğŸ“Š Input metadata: {sample_metadata['title']}")
        print(f"âš¡ Derived filters:")
        for key, value in filters.items():
            print(f"   {key}: {value}")
        
        # Test collection mapping
        collection = FilterEngine.get_collection_mapping(sample_metadata)
        print(f"ğŸ“ Mapped collection: {collection}")
        
        if filters and collection:
            print("âœ… FilterEngine working correctly")
            return True
        else:
            print("âŒ FilterEngine not generating filters")
            return False
            
    except ImportError as e:
        print(f"âŒ FilterEngine import error: {e}")
        return False
    except Exception as e:
        print(f"âŒ FilterEngine test error: {e}")
        return False

def test_data_integrity():
    """Validate data integrity aprÃ¨s migration"""
    
    print("\nğŸ” DATA INTEGRITY TEST")
    print("=" * 40)
    
    questions_files = glob.glob("data/**/*questions.json", recursive=True)
    integrity_issues = []
    valid_files = 0
    
    for qfile in questions_files:
        try:
            with open(qfile, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Check required fields
            if "main_question" not in data:
                integrity_issues.append(f"Missing main_question: {qfile}")
                continue
            
            if "question_variants" not in data:
                integrity_issues.append(f"Missing question_variants: {qfile}")
                continue
            
            # Check data quality
            if not data["main_question"].strip():
                integrity_issues.append(f"Empty main_question: {qfile}")
                continue
            
            if not isinstance(data["question_variants"], list):
                integrity_issues.append(f"Invalid question_variants type: {qfile}")
                continue
            
            valid_files += 1
            
        except json.JSONDecodeError:
            integrity_issues.append(f"Invalid JSON: {qfile}")
        except Exception as e:
            integrity_issues.append(f"Error reading {qfile}: {e}")
    
    print(f"ğŸ“Š Files checked: {len(questions_files)}")
    print(f"âœ… Valid files: {valid_files}")
    print(f"âŒ Issues found: {len(integrity_issues)}")
    
    if integrity_issues:
        print("âš ï¸  Issues:")
        for issue in integrity_issues[:5]:  # Show first 5
            print(f"   {issue}")
        if len(integrity_issues) > 5:
            print(f"   ... and {len(integrity_issues) - 5} more")
    
    success_rate = (valid_files / len(questions_files)) * 100 if questions_files else 0
    print(f"ğŸ“ˆ Success rate: {success_rate:.1f}%")
    
    return success_rate >= 95

def test_performance_comparison():
    """Test performance cá»§a new vs old approach"""
    
    print("\nâš¡ PERFORMANCE COMPARISON")
    print("=" * 40)
    
    # Find sample files Ä‘á»ƒ test
    questions_files = glob.glob("data/**/*questions.json", recursive=True)
    
    if not questions_files:
        print("âŒ No questions.json files found")
        return False
    
    sample_files = questions_files[:10]  # Test vá»›i 10 files
    
    # Test new approach (questions.json + document.json)
    start_time = time.time()
    for qfile in sample_files:
        with open(qfile, 'r', encoding='utf-8') as f:
            questions_data = json.load(f)
        
        # Load corresponding document.json
        doc_dir = os.path.dirname(qfile)
        doc_files = [f for f in os.listdir(doc_dir) 
                    if f.endswith('.json') and f not in ['questions.json', 'router_questions.json']]
        
        if doc_files:
            doc_path = os.path.join(doc_dir, doc_files[0])
            with open(doc_path, 'r', encoding='utf-8') as f:
                doc_data = json.load(f)
    
    new_approach_time = time.time() - start_time
    
    # Compare with backup files if available
    backup_files = glob.glob("migration_backup_*/**/*router_questions.json", recursive=True)
    
    if backup_files:
        sample_backup = backup_files[:10]
        
        start_time = time.time()
        for bfile in sample_backup:
            with open(bfile, 'r', encoding='utf-8') as f:
                backup_data = json.load(f)
        
        old_approach_time = time.time() - start_time
        
        improvement = ((old_approach_time - new_approach_time) / old_approach_time) * 100
        
        print(f"ğŸ“Š Performance test (10 files):")
        print(f"   Old approach: {old_approach_time:.3f}s")
        print(f"   New approach: {new_approach_time:.3f}s")
        print(f"   Improvement: {improvement:.1f}%")
        
        return improvement > 0
    else:
        print(f"ğŸ“Š New approach: {new_approach_time:.3f}s (10 files)")
        print("âš ï¸  No backup files for comparison")
        return True

def generate_final_report():
    """Generate comprehensive final report"""
    
    storage_results = test_storage_reduction()
    filter_engine_ok = test_filter_engine()
    data_integrity_ok = test_data_integrity()
    performance_ok = test_performance_comparison()
    
    report = {
        "migration_date": time.strftime("%Y-%m-%d %H:%M:%S"),
        "storage_reduction": storage_results,
        "filter_engine_test": filter_engine_ok,
        "data_integrity_test": data_integrity_ok,
        "performance_test": performance_ok,
        "overall_success": all([filter_engine_ok, data_integrity_ok, performance_ok])
    }
    
    # Save report
    report_path = f"final_migration_report_{int(time.time())}.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 60)
    print("ğŸ¯ FINAL MIGRATION REPORT")
    print("=" * 60)
    print(f"ğŸ“Š Storage Reduction: {storage_results['reduction_percent']:.1f}%")
    print(f"ğŸ”§ FilterEngine: {'âœ…' if filter_engine_ok else 'âŒ'}")
    print(f"ğŸ” Data Integrity: {'âœ…' if data_integrity_ok else 'âŒ'}")
    print(f"âš¡ Performance: {'âœ…' if performance_ok else 'âŒ'}")
    print(f"ğŸ‰ Overall Success: {'âœ…' if report['overall_success'] else 'âŒ'}")
    print(f"ğŸ“‹ Report saved: {report_path}")
    
    return report

if __name__ == "__main__":
    print("ğŸ§ª COMPREHENSIVE TESTING SUITE")
    print("Final validation of migration success")
    print()
    
    report = generate_final_report()
    
    if report["overall_success"]:
        print("\nğŸ‰ MIGRATION COMPLETELY SUCCESSFUL!")
        print("âœ… God object pattern eliminated")
        print("âœ… Clean architecture implemented")
        print("âœ… All tests passed")
    else:
        print("\nâš ï¸  MIGRATION NEEDS ATTENTION")
        print("Review test results above")
