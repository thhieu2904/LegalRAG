#!/usr/bin/env python3
"""
Script debug search results - Hiá»ƒn thá»‹ Ä‘áº§y Ä‘á»§ ná»™i dung vÃ  phÃ¢n tÃ­ch
"""

import sys
import json
from pathlib import Path
from typing import List, Dict, Any

# Add backend to path
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from app.core.config import settings
from app.services.vectordb_service import VectorDBService

def analyze_search_results(query: str, top_k: int = 10, similarity_threshold: float = 0.2):
    """
    PhÃ¢n tÃ­ch káº¿t quáº£ tÃ¬m kiáº¿m chi tiáº¿t
    """
    print(f"ğŸ” PHÃ‚N TÃCH Káº¾T QUáº¢ TÃŒM KIáº¾M")
    print("=" * 80)
    print(f"Query: '{query}'")
    print(f"Top K: {top_k}, Similarity Threshold: {similarity_threshold}")
    print()
    
    # Setup service
    settings.setup_environment()
    vectordb_service = VectorDBService()
    
    # Search across all collections
    all_results = []
    
    # Get all collections
    collections = vectordb_service.client.list_collections()
    print(f"ğŸ“š Available Collections: {[c.name for c in collections]}")
    print()
    
    for collection in collections:
        collection_name = collection.name
        print(f"ğŸ” Searching in collection: {collection_name}")
        
        results = vectordb_service.search_in_collection(
            collection_name=collection_name,
            query=query,
            top_k=top_k,
            similarity_threshold=similarity_threshold
        )
        
        print(f"   Found: {len(results)} results")
        
        for result in results:
            result['collection'] = collection_name
            all_results.append(result)
    
    # Sort by similarity
    all_results.sort(key=lambda x: x.get('similarity', 0), reverse=True)
    
    print(f"\nğŸ“Š Tá»”NG Káº¾T: {len(all_results)} káº¿t quáº£ tÃ¬m Ä‘Æ°á»£c")
    print("=" * 80)
    
    # Analyze results
    for i, result in enumerate(all_results, 1):
        print(f"\nğŸ¯ Káº¾T QUáº¢ {i}")
        print("-" * 50)
        
        # Basic info
        similarity = result.get('similarity', 0)
        collection = result.get('collection', 'unknown')
        print(f"ğŸ“Š Similarity: {similarity:.4f}")
        print(f"ğŸ“ Collection: {collection}")
        
        # Metadata analysis
        metadata = result.get('metadata', {})
        print(f"ğŸ“„ Document Title: {metadata.get('document_title', 'N/A')}")
        print(f"ğŸ“ Section Title: {metadata.get('section_title', 'N/A')}")
        print(f"ğŸ†” Chunk ID: {metadata.get('chunk_id', 'N/A')}")
        print(f"ğŸ“ Chunk Index: {metadata.get('chunk_index_num', 'N/A')}")
        
        # Content analysis
        content = result.get('content', '')
        print(f"ğŸ“ Content Length: {len(content)} characters")
        print()
        print("ğŸ“– FULL CONTENT:")
        print("â”€" * 60)
        print(content)
        print("â”€" * 60)
        
        # Keywords analysis
        keywords = result.get('keywords', [])
        if keywords:
            print(f"ğŸ·ï¸  Keywords: {', '.join(keywords)}")
        
        # Source info
        source = result.get('source', {})
        file_path = source.get('file_path', 'N/A')
        print(f"ğŸ“‚ Source File: {Path(file_path).name if file_path != 'N/A' else 'N/A'}")
        
        print("\n" + "=" * 80)
    
    # Summary analysis
    print(f"\nğŸ“ˆ PHÃ‚N TÃCH Tá»”NG Káº¾T")
    print("=" * 80)
    
    # Collection distribution
    collection_counts = {}
    document_titles = {}
    
    for result in all_results:
        coll = result.get('collection', 'unknown')
        collection_counts[coll] = collection_counts.get(coll, 0) + 1
        
        title = result.get('metadata', {}).get('document_title', 'N/A')
        document_titles[title] = document_titles.get(title, 0) + 1
    
    print("ğŸ“Š Distribution by Collection:")
    for coll, count in collection_counts.items():
        print(f"   - {coll}: {count} results")
    
    print("\nğŸ“‘ Distribution by Document:")
    for title, count in sorted(document_titles.items(), key=lambda x: x[1], reverse=True):
        if title != 'N/A':
            print(f"   - {title}: {count} results")
    
    # Similarity analysis
    if all_results:
        similarities = [r.get('similarity', 0) for r in all_results]
        print(f"\nğŸ¯ Similarity Scores:")
        print(f"   - Highest: {max(similarities):.4f}")
        print(f"   - Lowest: {min(similarities):.4f}")
        print(f"   - Average: {sum(similarities)/len(similarities):.4f}")

def interactive_search():
    """
    Interactive search Ä‘á»ƒ user cÃ³ thá»ƒ test nhiá»u queries
    """
    print("ğŸš€ INTERACTIVE SEARCH DEBUG")
    print("=" * 50)
    print("Nháº­p query Ä‘á»ƒ tÃ¬m kiáº¿m (hoáº·c 'quit' Ä‘á»ƒ thoÃ¡t)")
    print("VÃ­ dá»¥: 'thá»§ tá»¥c khai sinh', 'khai sinh thÃ´ng thÆ°á»ng', etc.")
    print()
    
    while True:
        try:
            query = input("ğŸ” Query: ").strip()
            
            if query.lower() in ['quit', 'exit', 'q']:
                print("ğŸ‘‹ Bye!")
                break
                
            if not query:
                print("âš ï¸  Vui lÃ²ng nháº­p query!")
                continue
            
            print()
            analyze_search_results(query, top_k=5, similarity_threshold=0.1)
            print("\n" + "="*80 + "\n")
            
        except KeyboardInterrupt:
            print("\nğŸ‘‹ Bye!")
            break
        except Exception as e:
            print(f"âŒ Error: {e}")

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='Debug search results')
    parser.add_argument('--query', '-q', type=str, help='Search query')
    parser.add_argument('--interactive', '-i', action='store_true', help='Interactive mode')
    parser.add_argument('--top-k', '-k', type=int, default=10, help='Number of results')
    parser.add_argument('--threshold', '-t', type=float, default=0.2, help='Similarity threshold')
    
    args = parser.parse_args()
    
    if args.interactive:
        interactive_search()
    elif args.query:
        analyze_search_results(args.query, args.top_k, args.threshold)
    else:
        # Default test
        test_query = "thá»§ tá»¥c khai sinh"
        analyze_search_results(test_query, top_k=5, similarity_threshold=0.1)
