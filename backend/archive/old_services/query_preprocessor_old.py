"""
Query Preprocessor Service - Module Ti·ªÅn x·ª≠ l√Ω Th√¥ng minh
X·ª≠ l√Ω c√¢u h·ªèi tr∆∞·ªõc khi ƒë∆∞a v√†o RAG ƒë·ªÉ:
1. L√†m r√µ c√¢u h·ªèi m∆° h·ªì
2. Qu·∫£n l√Ω l·ªãch s·ª≠ h·ªôi tho·∫°i hi·ªáu qu·∫£
3. T·∫°o context-aware query t·ª´ conversation history
"""

import logging
import time
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass

logger = logging.getLogger(__name__)

@dataclass
class ConversationTurn:
    """L∆∞u tr·ªØ m·ªôt l∆∞·ª£t h·ªôi tho·∫°i"""
    user_query: str
    assistant_response: str
    timestamp: float
    topic_tags: Optional[List[str]] = None  # Tags ch·ªß ƒë·ªÅ ƒë·ªÉ n√©n l·ªãch s·ª≠

class QueryPreprocessor:
    """
    Module ti·ªÅn x·ª≠ l√Ω th√¥ng minh cho RAG system
    """
    
    def __init__(self, llm_service):
        self.llm_service = llm_service
        self.conversation_history: List[ConversationTurn] = []
        self.max_history_length = 10  # Gi·ªõi h·∫°n l·ªãch s·ª≠ ƒë·ªÉ ti·∫øt ki·ªám VRAM
        
        # Templates cho c√°c lo·∫°i x·ª≠ l√Ω kh√°c nhau
        self.clarification_template = """B·∫°n l√† chuy√™n gia ph√¢n t√≠ch c√¢u h·ªèi ph√°p lu·∫≠t. Ph√¢n t√≠ch c√¢u h·ªèi v√† x√°c ƒë·ªãnh c√≥ c·∫ßn l√†m r√µ kh√¥ng.

### Quy t·∫Øc ph√¢n t√≠ch NGHI√äM NG·∫∂T:
1. N·∫øu c√¢u h·ªèi c√≥ ƒê·ª¶ th√¥ng tin c·ª• th·ªÉ ‚Üí tr·∫£ l·ªùi "CLEAR"
2. N·∫øu c√¢u h·ªèi thi·∫øu b·∫•t k·ª≥ th√¥ng tin quan tr·ªçng n√†o ‚Üí Y√äU C·∫¶U L√ÄM R√ï

### C√°c d·∫•u hi·ªáu B·∫ÆT BU·ªòC l√†m r√µ:
- Thi·∫øu ƒë·ªëi t∆∞·ª£ng c·ª• th·ªÉ: "m√¨nh/t√¥i/anh/ch·ªã" (c·∫ßn bi·∫øt c√¥ng d√¢n VN hay n∆∞·ªõc ngo√†i)
- Thi·∫øu lo·∫°i th·ªß t·ª•c: "nh·∫≠n con nu√¥i" (trong n∆∞·ªõc hay qu·ªëc t·∫ø? ƒë∆°n th√¢n hay v·ª£ ch·ªìng?)
- Thi·∫øu ng·ªØ c·∫£nh: "l√†m g√¨?" (c·∫ßn bi·∫øt t√¨nh hu·ªëng c·ª• th·ªÉ)
- T·ª´ m∆° h·ªì: "th·ªß t·ª•c n√†y", "vi·ªác ƒë√≥", "nh∆∞ th·∫ø n√†o"

### V√≠ d·ª• c√¢u h·ªèi C·∫¶N l√†m r√µ:
- "m√¨nh mu·ªën l√†m th·ªß t·ª•c nh·∫≠n nu√¥i con" ‚Üí C·∫ßn h·ªèi: ƒë·ªëi t∆∞·ª£ng? lo·∫°i con nu√¥i?
- "l√†m sao ƒë·ªÉ k·∫øt h√¥n?" ‚Üí C·∫ßn h·ªèi: c√¥ng d√¢n VN? k·∫øt h√¥n v·ªõi ai?
- "th·ªß t·ª•c n√†y c·∫ßn g√¨?" ‚Üí C·∫ßn h·ªèi: th·ªß t·ª•c n√†o c·ª• th·ªÉ?

### C√¢u h·ªèi c·∫ßn ph√¢n t√≠ch:
{user_query}

### Ph√¢n t√≠ch (n·∫øu c·∫ßn l√†m r√µ, ƒë∆∞a ra 2-3 c√¢u h·ªèi c·ª• th·ªÉ):"""

        self.context_synthesis_template = """B·∫°n l√† tr·ª£ l√Ω t·ªïng h·ª£p th√¥ng tin. D·ª±a v√†o l·ªãch s·ª≠ h·ªôi tho·∫°i, t·∫°o m·ªôt c√¢u h·ªèi ƒë·ªôc l·∫≠p, ƒë·∫ßy ƒë·ªß ng·ªØ c·∫£nh.

### Nguy√™n t·∫Øc t·ªïng h·ª£p:
1. K·∫øt h·ª£p c√¢u h·ªèi m·ªõi v·ªõi ng·ªØ c·∫£nh t·ª´ l·ªãch s·ª≠
2. T·∫°o c√¢u h·ªèi C·ª§ TH·ªÇ, ƒê·ª¶ TH√îNG TIN ƒë·ªÉ t√¨m ki·∫øm
3. Gi·ªØ √Ω ƒë·ªãnh ch√≠nh c·ªßa ng∆∞·ªùi d√πng
4. Lo·∫°i b·ªè th√¥ng tin kh√¥ng li√™n quan

### L·ªãch s·ª≠ h·ªôi tho·∫°i:
{conversation_history}

### C√¢u h·ªèi hi·ªán t·∫°i:
{current_query}

### C√¢u h·ªèi t·ªïng h·ª£p (tr·∫£ v·ªÅ CH·ªà c√¢u h·ªèi, kh√¥ng gi·∫£i th√≠ch):"""

        self.topic_extraction_template = """Tr√≠ch xu·∫•t 2-3 t·ª´ kh√≥a ch√≠nh t·ª´ c√¢u tr·∫£ l·ªùi ƒë·ªÉ g·∫Øn tag ch·ªß ƒë·ªÅ.

### N·ªôi dung:
{content}

### T·ª´ kh√≥a ch·ªß ƒë·ªÅ (ph√¢n c√°ch b·∫±ng d·∫•u ph·∫©y):"""

    def add_conversation_turn(self, user_query: str, assistant_response: str, topic_tags: Optional[List[str]] = None):
        """Th√™m m·ªôt l∆∞·ª£t h·ªôi tho·∫°i v√†o l·ªãch s·ª≠"""
        turn = ConversationTurn(
            user_query=user_query,
            assistant_response=assistant_response,
            timestamp=time.time(),
            topic_tags=topic_tags or []
        )
        
        self.conversation_history.append(turn)
        
        # Gi·ªõi h·∫°n ƒë·ªô d√†i l·ªãch s·ª≠ ƒë·ªÉ ti·∫øt ki·ªám VRAM
        if len(self.conversation_history) > self.max_history_length:
            # Gi·ªØ l·∫°i c√°c turn g·∫ßn ƒë√¢y nh·∫•t
            self.conversation_history = self.conversation_history[-self.max_history_length:]
        
        logger.debug(f"Added conversation turn. History length: {len(self.conversation_history)}")

    def extract_topic_tags(self, content: str) -> List[str]:
        """Tr√≠ch xu·∫•t topic tags t·ª´ n·ªôi dung ƒë·ªÉ n√©n l·ªãch s·ª≠"""
        try:
            prompt = self.topic_extraction_template.format(content=content[:500])
            
            result = self.llm_service.generate_response(
                user_query=prompt,
                max_tokens=50,
                temperature=0.1,
                system_prompt="B·∫°n l√† tr·ª£ l√Ω tr√≠ch xu·∫•t t·ª´ kh√≥a."
            )
            
            tags_text = result['response'].strip()
            tags = [tag.strip() for tag in tags_text.split(',') if tag.strip()]
            return tags[:3]  # Ch·ªâ l·∫•y t·ªëi ƒëa 3 tags
            
        except Exception as e:
            logger.error(f"Error extracting topic tags: {e}")
            return []

    def analyze_query_clarity(self, user_query: str) -> Dict[str, Any]:
        """
        Ph√¢n t√≠ch xem c√¢u h·ªèi c√≥ c·∫ßn l√†m r√µ kh√¥ng
        Returns: {'needs_clarification': bool, 'clarification_questions': List[str], 'analysis': str}
        """
        try:
            prompt = self.clarification_template.format(user_query=user_query)
            
            result = self.llm_service.generate_response(
                user_query=prompt,
                max_tokens=200,
                temperature=0.3,
                system_prompt="B·∫°n l√† chuy√™n gia ph√¢n t√≠ch c√¢u h·ªèi ph√°p lu·∫≠t."
            )
            
            analysis = result['response'].strip()
            
            # Parse k·∫øt qu·∫£
            if "CLEAR" in analysis.upper():
                return {
                    'needs_clarification': False,
                    'clarification_questions': [],
                    'analysis': analysis,
                    'confidence': 'high'
                }
            else:
                # Tr√≠ch xu·∫•t c√°c c√¢u h·ªèi l√†m r√µ
                lines = analysis.split('\n')
                questions = []
                for line in lines:
                    line = line.strip()
                    if line and ('?' in line or line.startswith('-') or line.startswith('‚Ä¢')):
                        questions.append(line.lstrip('- ‚Ä¢').strip())
                
                return {
                    'needs_clarification': len(questions) > 0,
                    'clarification_questions': questions[:3],  # T·ªëi ƒëa 3 c√¢u h·ªèi
                    'analysis': analysis,
                    'confidence': 'medium' if len(questions) > 0 else 'low'
                }
                
        except Exception as e:
            logger.error(f"Error analyzing query clarity: {e}")
            return {
                'needs_clarification': False,
                'clarification_questions': [],
                'analysis': f"Error: {str(e)}",
                'confidence': 'error'
            }

    def synthesize_contextual_query(self, current_query: str) -> str:
        """
        T·ªïng h·ª£p c√¢u h·ªèi hi·ªán t·∫°i v·ªõi ng·ªØ c·∫£nh t·ª´ l·ªãch s·ª≠ h·ªôi tho·∫°i
        Tr·∫£ v·ªÅ c√¢u h·ªèi ƒë·ªôc l·∫≠p, ƒë·∫ßy ƒë·ªß ng·ªØ c·∫£nh
        """
        if not self.conversation_history:
            return current_query
        
        try:
            # T·∫°o t√≥m t·∫Øt l·ªãch s·ª≠ n√©n g·ªçn
            history_summary = self._create_compressed_history()
            
            prompt = self.context_synthesis_template.format(
                conversation_history=history_summary,
                current_query=current_query
            )
            
            result = self.llm_service.generate_response(
                user_query=prompt,
                max_tokens=150,
                temperature=0.2,
                system_prompt="B·∫°n l√† tr·ª£ l√Ω t·ªïng h·ª£p th√¥ng tin chuy√™n nghi·ªáp."
            )
            
            synthesized_query = result['response'].strip()
            
            # Validate k·∫øt qu·∫£
            if len(synthesized_query) > 10 and '?' in synthesized_query:
                logger.info(f"Query synthesized: '{current_query}' ‚Üí '{synthesized_query}'")
                return synthesized_query
            else:
                logger.warning("Synthesis failed, using original query")
                return current_query
                
        except Exception as e:
            logger.error(f"Error synthesizing contextual query: {e}")
            return current_query

    def _create_compressed_history(self) -> str:
        """T·∫°o t√≥m t·∫Øt l·ªãch s·ª≠ h·ªôi tho·∫°i n√©n g·ªçn"""
        if not self.conversation_history:
            return ""
        
        # Ch·ªâ l·∫•y 5 l∆∞·ª£t g·∫ßn nh·∫•t ƒë·ªÉ tr√°nh context qu√° d√†i
        recent_history = self.conversation_history[-5:]
        
        compressed_items = []
        for i, turn in enumerate(recent_history):
            # R√∫t g·ªçn c√¢u tr·∫£ l·ªùi ch·ªâ gi·ªØ √Ω ch√≠nh
            response_summary = turn.assistant_response[:200] + "..." if len(turn.assistant_response) > 200 else turn.assistant_response
            
            compressed_items.append(f"L·∫ßn {i+1}:")
            compressed_items.append(f"Q: {turn.user_query}")
            compressed_items.append(f"A: {response_summary}")
            if turn.topic_tags:
                compressed_items.append(f"Tags: {', '.join(turn.topic_tags)}")
            compressed_items.append("")  # Empty line separator
        
        return '\n'.join(compressed_items)

    def process_query(
        self, 
        user_query: str, 
        enable_clarification: bool = True,
        enable_context_synthesis: bool = True,
        clarification_threshold: str = 'medium'  # 'low', 'medium', 'high'
    ) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω c√¢u h·ªèi ƒë·∫ßy ƒë·ªß v·ªõi t·∫•t c·∫£ c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω
        
        Returns:
        {
            'processed_query': str,  # C√¢u h·ªèi ƒë√£ x·ª≠ l√Ω 
            'needs_clarification': bool,
            'clarification_questions': List[str],
            'processing_steps': List[str],
            'original_query': str,
            'context_synthesized': bool
        }
        """
        start_time = time.time()
        processing_steps = []
        
        result = {
            'processed_query': user_query,
            'needs_clarification': False,
            'clarification_questions': [],
            'processing_steps': processing_steps,
            'original_query': user_query,
            'context_synthesized': False,
            'processing_time': 0
        }
        
        try:
            # B∆Ø·ªöC 1: Context Synthesis (∆∞u ti√™n tr∆∞·ªõc)
            if enable_context_synthesis and self.conversation_history:
                processing_steps.append("context_synthesis")
                synthesized_query = self.synthesize_contextual_query(user_query)
                if synthesized_query != user_query:
                    result['processed_query'] = synthesized_query
                    result['context_synthesized'] = True
                    logger.info("Context synthesis applied")
                else:
                    processing_steps.append("context_synthesis_skipped")
            
            # B∆Ø·ªöC 2: Clarity Analysis
            if enable_clarification:
                processing_steps.append("clarity_analysis")
                clarity_result = self.analyze_query_clarity(result['processed_query'])
                
                # LOGIC M·∫†NH H∆†N: Lu√¥n ∆∞u ti√™n clarification n·∫øu ph√°t hi·ªán m∆° h·ªì
                if clarity_result['needs_clarification']:
                    result['needs_clarification'] = True
                    result['clarification_questions'] = clarity_result['clarification_questions']
                    processing_steps.append("clarification_required")
                    logger.info(f"ü§î Clarification required for: '{user_query}' - {len(result['clarification_questions'])} questions")
                    logger.info(f"Questions: {result['clarification_questions']}")
                else:
                    processing_steps.append("clarity_sufficient")
                    logger.info(f"‚úÖ Query clear enough: '{user_query}'")
            
            result['processing_time'] = time.time() - start_time
            logger.info(f"Query processing completed in {result['processing_time']:.2f}s with steps: {processing_steps}")
            
            return result
            
        except Exception as e:
            logger.error(f"Error in query processing: {e}")
            result['processing_steps'].append("error")
            result['processing_time'] = time.time() - start_time
            return result

    def clear_history(self):
        """X√≥a l·ªãch s·ª≠ h·ªôi tho·∫°i"""
        self.conversation_history.clear()
        logger.info("Conversation history cleared")

    def get_history_summary(self) -> Dict[str, Any]:
        """L·∫•y t√≥m t·∫Øt l·ªãch s·ª≠ h·ªôi tho·∫°i"""
        if not self.conversation_history:
            return {
                'total_turns': 0,
                'topics': [],
                'recent_queries': []
            }
        
        # Thu th·∫≠p t·∫•t c·∫£ topics
        all_topics = []
        for turn in self.conversation_history:
            all_topics.extend(turn.topic_tags or [])
        
        unique_topics = list(set(all_topics))
        recent_queries = [turn.user_query for turn in self.conversation_history[-3:]]
        
        return {
            'total_turns': len(self.conversation_history),
            'topics': unique_topics,
            'recent_queries': recent_queries,
            'oldest_timestamp': self.conversation_history[0].timestamp if self.conversation_history else None,
            'newest_timestamp': self.conversation_history[-1].timestamp if self.conversation_history else None
        }
