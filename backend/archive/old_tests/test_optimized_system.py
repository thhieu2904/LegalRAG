#!/usr/bin/env python3
"""
Test Optimized RAG System with GPU Support and Anti-Repetition
Tests both performance and response quality improvements
"""

import asyncio
import json
import time
from app.services.rag_service import RAGService
from app.services.vectordb_service import VectorDBService
from app.services.llm_service import LLMService
from app.core.config import settings

async def test_optimized_rag():
    """Test RAG system v·ªõi GPU acceleration v√† anti-repetition"""
    
    print("="*70)
    print("üöÄ TESTING OPTIMIZED RAG SYSTEM")
    print("="*70)
    print(f"üìä Config Summary:")
    print(f"   ‚Ä¢ GPU Layers: {settings.n_gpu_layers} (-1 = all on GPU)")
    print(f"   ‚Ä¢ CPU Threads: {settings.n_threads}")
    print(f"   ‚Ä¢ Batch Size: {settings.n_batch}")
    print(f"   ‚Ä¢ Max Tokens: {settings.max_tokens}")
    print(f"   ‚Ä¢ Temperature: {settings.temperature}")
    print()
    
    try:
        # Kh·ªüi t·∫°o services
        print("üîß Initializing services...")
        vectordb_service = VectorDBService()
        llm_service = LLMService()
        
        print(f"   ‚úÖ VectorDB: {vectordb_service.embedding_model_name}")
        print(f"   ‚úÖ LLM: {'GPU-accelerated' if settings.n_gpu_layers != 0 else 'CPU-only'}")
        print()
        
        rag_service = RAGService(
            documents_dir=str(settings.documents_path),
            vectordb_service=vectordb_service,
            llm_service=llm_service
        )
        
        # Health check
        health = rag_service.get_health_status()
        print(f"üè• System Health: {health['status']}")
        print(f"   ‚Ä¢ Collections: {health['total_collections']}")
        print(f"   ‚Ä¢ Documents: {health['total_documents']}")
        print(f"   ‚Ä¢ GPU Available: {health['model_info'].get('n_gpu_layers', 0) != 0}")
        print()
        
        # Test queries v·ªõi focus v√†o repetition problem
        test_queries = [
            "th·ªß t·ª•c nu√¥i con nu√¥i",  # Query g√¢y l·∫∑p tr∆∞·ªõc ƒë√¢y
            "c√°ch ƒëƒÉng k√Ω khai sinh",
            "th·ªß t·ª•c ch·ª©ng th·ª±c b·∫£n sao"
        ]
        
        results = []
        for i, query in enumerate(test_queries, 1):
            print(f"üîç Test {i}/3: '{query}'")
            print("-" * 50)
            
            start_time = time.time()
            result = rag_service.query(
                question=query,
                max_tokens=256,  # Gi·ªõi h·∫°n ƒë·ªÉ test anti-repetition
                temperature=0.3   # TƒÉng ƒë·ªÉ tr√°nh l·∫∑p
            )
            processing_time = time.time() - start_time
            
            # Extract key metrics
            answer = result['answer']
            sources_count = len(result.get('sources', []))
            tokens_used = result.get('tokens_used', 0)
            llm_time = result.get('llm_processing_time', 0)
            
            # Check for repetition issues
            answer_lines = answer.split('\n')
            repetitive_lines = sum(1 for line in answer_lines if answer_lines.count(line) > 2 and line.strip())
            
            print(f"   ‚ö° Total Time: {processing_time:.2f}s")
            print(f"   üß† LLM Time: {llm_time:.2f}s")
            print(f"   üìù Tokens: {tokens_used}")
            print(f"   üìö Sources: {sources_count}")
            print(f"   üîÑ Repetitive Lines: {repetitive_lines}")
            print(f"   üìè Answer Length: {len(answer)} chars")
            print()
            print(f"   üí¨ Answer Preview:")
            preview = answer[:300].replace('\n', ' ')
            print(f"   {preview}{'...' if len(answer) > 300 else ''}")
            print()
            
            results.append({
                'query': query,
                'processing_time': processing_time,
                'llm_time': llm_time,
                'tokens': tokens_used,
                'sources': sources_count,
                'repetitive_lines': repetitive_lines,
                'answer_length': len(answer),
                'has_repetition_issue': repetitive_lines > 0,
                'answer': answer
            })
        
        # Summary report
        print("="*70)
        print("üìä PERFORMANCE & QUALITY SUMMARY")
        print("="*70)
        
        avg_total_time = sum(r['processing_time'] for r in results) / len(results)
        avg_llm_time = sum(r['llm_time'] for r in results) / len(results)
        total_repetition_issues = sum(1 for r in results if r['has_repetition_issue'])
        
        print(f"‚ö° Average Performance:")
        print(f"   ‚Ä¢ Total Processing: {avg_total_time:.2f}s")
        print(f"   ‚Ä¢ LLM Generation: {avg_llm_time:.2f}s")
        print(f"   ‚Ä¢ GPU/CPU Ratio: ~{(1 - avg_llm_time/avg_total_time)*100:.0f}% non-LLM / {(avg_llm_time/avg_total_time)*100:.0f}% LLM")
        print()
        
        print(f"üîÑ Quality Assessment:")
        print(f"   ‚Ä¢ Queries with Repetition Issues: {total_repetition_issues}/{len(results)}")
        print(f"   ‚Ä¢ System Status: {'‚úÖ FIXED' if total_repetition_issues == 0 else '‚ùå STILL HAS ISSUES'}")
        
        # Performance recommendations
        print()
        print("üéØ Performance Analysis:")
        if avg_llm_time > 10:
            print("   ‚ö†Ô∏è  LLM processing still slow - check GPU utilization")
        elif avg_llm_time < 2:
            print("   ‚úÖ Excellent LLM performance - GPU acceleration working")
        else:
            print("   ‚úÖ Good LLM performance")
            
        if total_repetition_issues == 0:
            print("   ‚úÖ Anti-repetition measures successful")
        else:
            print("   ‚ö†Ô∏è  Still has repetition issues - need further tuning")
        
        return results
        
    except Exception as e:
        print(f"‚ùå Test failed: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(test_optimized_rag())
