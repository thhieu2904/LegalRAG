import logging
import os
from pathlib import Path
from typing import List, Dict, Any, Tuple, Optional
from sentence_transformers import CrossEncoder
import numpy as np
from ..core.config import settings

logger = logging.getLogger(__name__)

class RerankerService:
    """Service qu·∫£n l√Ω Vietnamese Reranker model ƒë·ªÉ ch·∫•m l·∫°i ƒë·ªô li√™n quan"""
    
    def __init__(self, model_name: Optional[str] = None):
        self.model_name = model_name or settings.reranker_model_name
        self.model = None
        
        # Config ƒë√£ setup environment r·ªìi, kh√¥ng c·∫ßn _setup_cache n·ªØa
        self._load_model()
    
    def _load_model(self):
        """Load model t·ª´ cache local ho·∫∑c download n·∫øu c·∫ßn - GPU for optimal performance"""
        try:
            logger.info(f"Loading reranker model: {self.model_name}")
            
            # Th·ª≠ load t·ª´ local cache tr∆∞·ªõc - s·ª≠ d·ª•ng GPU
            local_model_path = self._get_local_model_path()
            if local_model_path and local_model_path.exists():
                logger.info(f"Found local model at: {local_model_path}")
                try:
                    self.model = CrossEncoder(str(local_model_path), device='cuda:0')
                    logger.info("Reranker model loaded successfully from local cache on GPU")
                    return
                except Exception as e:
                    logger.warning(f"Failed to load from local cache on GPU: {e}")
            
            # Fallback: load t·ª´ HuggingFace (s·∫Ω download n·∫øu c·∫ßn) - s·ª≠ d·ª•ng GPU
            logger.info("Loading from HuggingFace (may download) on GPU")
            self.model = CrossEncoder(self.model_name, device='cuda:0')
            logger.info("Reranker model loaded successfully from HuggingFace on GPU")
            
        except Exception as e:
            logger.error(f"Failed to load reranker model: {e}")
            self.model = None
            raise
    
    def _get_local_model_path(self):
        """T√¨m ƒë∆∞·ªùng d·∫´n local model n·∫øu c√≥"""
        try:
            # S·ª≠ d·ª•ng config path
            cache_hub_path = settings.hf_cache_path / "hub"
            model_dir = cache_hub_path / "models--AITeamVN--Vietnamese_Reranker"
            
            if model_dir.exists():
                # T√¨m snapshot directory
                snapshots_dir = model_dir / "snapshots"
                if snapshots_dir.exists():
                    # L·∫•y snapshot m·ªõi nh·∫•t
                    snapshot_dirs = [d for d in snapshots_dir.iterdir() if d.is_dir()]
                    if snapshot_dirs:
                        latest_snapshot = max(snapshot_dirs, key=lambda x: x.stat().st_mtime)
                        logger.info(f"Found local snapshot: {latest_snapshot}")
                        return latest_snapshot
            
            return None
        except Exception as e:
            logger.warning(f"Error finding local model path: {e}")
            return None
    
    def rerank_documents(
        self, 
        query: str, 
        documents: List[Dict[str, Any]], 
        top_k: Optional[int] = None,
        router_confidence: Optional[float] = None,
        router_confidence_level: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """
        Rerank danh s√°ch documents d·ª±a tr√™n ƒë·ªô li√™n quan v·ªõi query
        
        Args:
            query: C√¢u h·ªèi c·∫ßn t√¨m
            documents: Danh s√°ch documents c·∫ßn rerank
            top_k: S·ªë l∆∞·ª£ng documents t·ªët nh·∫•t c·∫ßn tr·∫£ v·ªÅ (n·∫øu None th√¨ tr·∫£ v·ªÅ t·∫•t c·∫£)
            router_confidence: Confidence score t·ª´ router (0.0-1.0)
            router_confidence_level: Level t·ª´ router ('low', 'medium', 'high')
        
        Returns:
            Danh s√°ch documents ƒë√£ ƒë∆∞·ª£c s·∫Øp x·∫øp l·∫°i theo ƒë·ªô li√™n quan
        """
        if not self.model:
            logger.warning("Reranker model not loaded, returning original order")
            return documents[:top_k] if top_k else documents
        
        if not documents:
            return []
        
        # üõ°Ô∏è ROUTER TRUST MODE: Khi router c√≥ HIGH confidence, tin t∆∞·ªüng router h∆°n
        trust_router = (router_confidence_level == 'high' and router_confidence and router_confidence >= 0.85)
        if trust_router:
            logger.info(f"üõ°Ô∏è ROUTER TRUST MODE: Router confidence {router_confidence:.3f} (HIGH) - Minimal rerank interference")
        
        try:
            # üîç DEBUG: Log query ƒë∆∞·ª£c truy·ªÅn v√†o reranker
            logger.info(f"üîç RERANK QUERY: '{query}' ({len(query)} chars)")
            
            # Chu·∫©n b·ªã pairs (query, document_content) cho reranker
            pairs = []
            for i, doc in enumerate(documents):
                # üîç DEBUG: Log document content ƒë·ªÉ ph√¢n t√≠ch
                content = doc['content']
                
                # üéØ INTELLIGENT CONTENT EXTRACTION for Vietnamese Reranker
                # Thay v√¨ truncate random, h√£y extract ph·∫ßn li√™n quan nh·∫•t
                query_keywords = self._extract_query_keywords(query)
                relevant_content = self._extract_relevant_content(content, query_keywords, max_length=800)
                
                if len(relevant_content) != len(content):
                    logger.info(f"üîß OPTIMIZED DOC[{i}] from {len(content)} to {len(relevant_content)} chars (focused content)")
                
                # Clean content: lo·∫°i b·ªè markdown symbols v√† k√Ω t·ª± ƒë·∫∑c bi·ªát
                cleaned_content = relevant_content.replace("**", "").replace("*", "").replace("#", "")
                cleaned_content = " ".join(cleaned_content.split())  # Normalize whitespace
                
                if len(cleaned_content) > 200:
                    logger.info(f"üîç RERANK DOC[{i}] sample: '{cleaned_content[:200]}...' (total: {len(cleaned_content)} chars)")
                else:
                    logger.info(f"üîç RERANK DOC[{i}] full: '{cleaned_content}' ({len(cleaned_content)} chars)")
                
                pairs.append((query, cleaned_content))
            
            # T√≠nh rerank scores
            logger.info(f"Reranking {len(documents)} documents")
            scores = self.model.predict(pairs)
            
            # G√°n ƒëi·ªÉm rerank v√†o m·ªói document
            reranked_docs = []
            for doc, score in zip(documents, scores):
                doc_copy = doc.copy()
                doc_copy['rerank_score'] = float(score)
                reranked_docs.append(doc_copy)
            
            # S·∫Øp x·∫øp theo rerank score gi·∫£m d·∫ßn
            reranked_docs.sort(key=lambda x: x['rerank_score'], reverse=True)
            
            # Log th√¥ng tin v·ªÅ top document
            if reranked_docs:
                top_doc = reranked_docs[0]
                logger.info(f"Top document after reranking: score={top_doc['rerank_score']:.4f}, "
                          f"similarity={top_doc.get('similarity', 'N/A')}")
                
                # üõ°Ô∏è ROUTER TRUST MODE: Kh√¥ng trigger conservative strategy khi router HIGH confidence
                if trust_router:
                    logger.info(f"üõ°Ô∏è TRUSTING ROUTER: Accepting rerank results without conservative override (router: {router_confidence:.3f})")
                elif top_doc['rerank_score'] < 0.2:
                    logger.warning(f"‚ö†Ô∏è  LOW RERANK SCORE ({top_doc['rerank_score']:.4f}) - Conservative strategy may be triggered")
            
            # Tr·∫£ v·ªÅ top_k documents n·∫øu ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh
            if top_k:
                return reranked_docs[:top_k]
            
            return reranked_docs
            
        except Exception as e:
            logger.error(f"Error during reranking: {e}")
            # Fallback v·ªÅ s·∫Øp x·∫øp theo similarity score ban ƒë·∫ßu
            return sorted(documents, key=lambda x: x.get('similarity', 0), reverse=True)[:top_k] if top_k else documents
    
    def _extract_query_keywords(self, query: str) -> List[str]:
        """Extract key terms t·ª´ query ƒë·ªÉ t√¨m n·ªôi dung li√™n quan"""
        # Lo·∫°i b·ªè stop words ti·∫øng Vi·ªát v√† gi·ªØ c√°c t·ª´ kh√≥a quan tr·ªçng
        stop_words = {'c√≥', 'l√†', 'c·ªßa', 'ƒë∆∞·ª£c', 'n√†y', 'cho', 't·ª´', 'v·ªõi', 'v√†', 'trong', 'khi', 'ƒë·ªÉ', 'th√¨', 'nh∆∞', 'v·ªÅ', 'theo', 'tr√™n', 'd∆∞·ªõi', 'b√™n', 'gi·ªØa', 'ngo√†i', 'sau', 'tr∆∞·ªõc'}
        
        # T√°ch t·ª´ v√† lo·∫°i b·ªè stop words
        words = query.lower().split()
        keywords = []
        
        for word in words:
            # Clean word (lo·∫°i b·ªè d·∫•u c√¢u)
            clean_word = word.strip('.,!?":;()[]{}')
            if len(clean_word) > 2 and clean_word not in stop_words:
                keywords.append(clean_word)
                
        # Add specialized legal terms
        legal_terms = {
            'ph√≠': ['ph√≠', 'l·ªá ph√≠', 'ti·ªÅn', 'chi ph√≠', 'mi·ªÖn ph√≠'],
            'gi·∫•y': ['gi·∫•y t·ªù', 'h·ªì s∆°', 't√†i li·ªáu', 'ch·ª©ng t·ª´'],
            'th·ªß t·ª•c': ['th·ªß t·ª•c', 'quy tr√¨nh', 'tr√¨nh t·ª±'],
            'ƒëƒÉng k√Ω': ['ƒëƒÉng k√Ω', 'khai b√°o', 'n·ªôp ƒë∆°n']
        }
        
        # M·ªü r·ªông keywords v·ªõi legal terms
        expanded_keywords = keywords.copy()
        for keyword in keywords:
            for category, terms in legal_terms.items():
                if keyword in terms:
                    expanded_keywords.extend([t for t in terms if t not in expanded_keywords])
        
        logger.info(f"üîë Query keywords: {expanded_keywords}")
        return expanded_keywords
    
    def _extract_relevant_content(self, content: str, keywords: List[str], max_length: int = 800) -> str:
        """Extract nh·ªØng ph·∫ßn c·ªßa content c√≥ ch·ª©a keywords quan tr·ªçng"""
        if len(content) <= max_length:
            return content
        
        content_lower = content.lower()
        
        # T√¨m c√°c c√¢u ch·ª©a keywords
        sentences = content.split('.')
        relevant_sentences = []
        score_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
                
            sentence_lower = sentence.lower()
            score = 0
            
            # T√≠nh score d·ª±a tr√™n s·ªë keywords matching
            for keyword in keywords:
                if keyword in sentence_lower:
                    score += len(keyword)  # T·ª´ d√†i h∆°n c√≥ weight cao h∆°n
            
            if score > 0:
                score_sentences.append((sentence, score))
        
        # S·∫Øp x·∫øp theo score gi·∫£m d·∫ßn
        score_sentences.sort(key=lambda x: x[1], reverse=True)
        
        # L·∫•y c√°c c√¢u c√≥ score cao nh·∫•t cho ƒë·∫øn khi ƒë·∫°t max_length
        selected_sentences = []
        current_length = 0
        
        for sentence, score in score_sentences:
            if current_length + len(sentence) <= max_length:
                selected_sentences.append(sentence)
                current_length += len(sentence)
            else:
                break
        
        if selected_sentences:
            relevant_content = '. '.join(selected_sentences)
            logger.info(f"üìÑ Extracted {len(selected_sentences)} relevant sentences from {len(sentences)} total")
            return relevant_content
        else:
            # Fallback: l·∫•y ph·∫ßn ƒë·∫ßu
            logger.info("‚ö†Ô∏è  No keyword matches found, using content start")
            return content[:max_length] + "..."
            return sorted(documents, key=lambda x: x.get('similarity', 0), reverse=True)[:top_k] if top_k else documents
    
    def get_best_document(self, query: str, documents: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
        """
        T√¨m document c√≥ ƒë·ªô li√™n quan cao nh·∫•t v·ªõi query
        
        Args:
            query: C√¢u h·ªèi c·∫ßn t√¨m
            documents: Danh s√°ch documents c·∫ßn ƒë√°nh gi√°
        
        Returns:
            Document c√≥ ƒëi·ªÉm rerank cao nh·∫•t
        """
        reranked = self.rerank_documents(query, documents, top_k=1)
        return reranked[0] if reranked else None
    
    def is_loaded(self) -> bool:
        """Ki·ªÉm tra xem model ƒë√£ ƒë∆∞·ª£c load ch∆∞a"""
        return self.model is not None
    
    def get_model_info(self) -> Dict[str, Any]:
        """L·∫•y th√¥ng tin v·ªÅ model"""
        return {
            'model_name': self.model_name,
            'is_loaded': self.is_loaded(),
            'model_type': 'CrossEncoder' if self.model else None
        }
