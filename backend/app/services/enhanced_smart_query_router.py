"""
Enhanced Smart Query Router Service
ƒê·ªãnh tuy·∫øn c√¢u h·ªèi ƒë·∫øn ƒë√∫ng collection d·ª±a tr√™n example questions database
"""

import logging
import numpy as np
import json
import os
from typing import Dict, List, Tuple, Optional, Any
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

logger = logging.getLogger(__name__)

class EnhancedSmartQueryRouter:
    """Router th√¥ng minh s·ª≠ d·ª•ng database example questions cho routing ch√≠nh x√°c"""
    
    def __init__(self, embedding_model: SentenceTransformer):
        self.embedding_model = embedding_model
        self.base_path = "data/router_examples"
        
        # Load configuration
        self.config = self._load_config()
        
        # Example questions database
        self.example_questions = {}
        self.question_vectors = {}
        self.collection_mappings = {}
        
        # Thresholds
        self.similarity_threshold = 0.3
        self.high_confidence_threshold = 0.5
        
        # Initialize database
        self._load_example_questions()
        self._initialize_question_vectors()
        
        logger.info(f"‚úÖ Enhanced Smart Query Router initialized with {len(self.collection_mappings)} collections")
    
    def _load_config(self) -> Dict[str, Any]:
        """Load configuration from index.json"""
        try:
            config_path = os.path.join(self.base_path, "index.json")
            if not os.path.exists(config_path):
                logger.warning(f"Config file not found: {config_path}")
                return {}
            
            with open(config_path, 'r', encoding='utf-8') as f:
                config = json.load(f)
            
            logger.info(f"üìã Loaded router configuration v{config.get('metadata', {}).get('version', '1.0')}")
            return config
            
        except Exception as e:
            logger.error(f"‚ùå Error loading config: {e}")
            return {}
    
    def _load_example_questions(self):
        """Load all example questions from JSON files"""
        try:
            collection_mappings = self.config.get('collection_mappings', {})
            
            for collection_name, mapping_info in collection_mappings.items():
                example_files = mapping_info.get('example_files', [])
                self.collection_mappings[collection_name] = {
                    'display_name': mapping_info.get('description', collection_name),
                    'total_questions': 0
                }
                
                collection_questions = []
                
                for file_path in example_files:
                    full_path = os.path.join(self.base_path, file_path)
                    if not os.path.exists(full_path):
                        logger.warning(f"Example file not found: {full_path}")
                        continue
                    
                    try:
                        with open(full_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        questions = data.get('example_questions', [])
                        for question_data in questions:
                            # Main question
                            main_question = {
                                'text': question_data['question'],
                                'collection': collection_name,
                                'source': data['metadata']['title'],
                                'keywords': question_data.get('semantic_keywords', []),
                                'type': 'main'
                            }
                            collection_questions.append(main_question)
                            
                            # Question variants
                            variants = question_data.get('question_variants', [])
                            for variant in variants:
                                variant_question = {
                                    'text': variant,
                                    'collection': collection_name,
                                    'source': data['metadata']['title'],
                                    'keywords': question_data.get('semantic_keywords', []),
                                    'type': 'variant'
                                }
                                collection_questions.append(variant_question)
                        
                        logger.info(f"üìö Loaded {len(questions)} procedures from {data['metadata']['title']}")
                        
                    except Exception as e:
                        logger.error(f"‚ùå Error loading {full_path}: {e}")
                        continue
                
                self.example_questions[collection_name] = collection_questions
                self.collection_mappings[collection_name]['total_questions'] = len(collection_questions)
                
                logger.info(f"üéØ Collection '{collection_name}': {len(collection_questions)} example questions")
                
        except Exception as e:
            logger.error(f"‚ùå Error loading example questions: {e}")
            raise
    
    def _initialize_question_vectors(self):
        """T√≠nh to√°n vectors cho t·∫•t c·∫£ example questions"""
        try:
            for collection_name, questions in self.example_questions.items():
                collection_vectors = []
                
                for question in questions:
                    # Combine question text with keywords for better representation
                    keywords_text = " ".join(question.get('keywords', []))
                    combined_text = f"{question['text']} {keywords_text}"
                    
                    # Create embedding
                    vector = self.embedding_model.encode([combined_text])[0]
                    collection_vectors.append(vector)
                
                if collection_vectors:
                    # Store vectors as numpy array for efficient similarity computation
                    self.question_vectors[collection_name] = np.array(collection_vectors)
                    logger.info(f"üéØ Vectorized {len(collection_vectors)} questions for {collection_name}")
                
        except Exception as e:
            logger.error(f"‚ùå Error initializing question vectors: {e}")
            raise
    
    def route_query(self, query: str) -> Dict[str, Any]:
        """
        ƒê·ªãnh tuy·∫øn c√¢u h·ªèi ƒë·∫øn collection ph√π h·ª£p nh·∫•t d·ª±a tr√™n example questions
        
        Returns:
            {
                'status': 'routed' | 'ambiguous' | 'no_match',
                'target_collection': str | None,
                'confidence': float,
                'all_scores': Dict[str, float],
                'display_name': str | None,
                'clarification_needed': bool,
                'matched_example': str | None,
                'source_procedure': str | None
            }
        """
        try:
            # Create vector for query
            query_vector = self.embedding_model.encode([query])[0]
            
            # Find best matching example question across all collections
            best_collection = None
            best_score = 0.0
            best_example = None
            best_source = None
            collection_scores = {}
            
            for collection_name, questions in self.example_questions.items():
                if collection_name not in self.question_vectors:
                    continue
                
                # Calculate similarities with all questions in this collection
                question_vectors = self.question_vectors[collection_name]
                similarities = cosine_similarity(
                    query_vector.reshape(1, -1),
                    question_vectors
                )[0]
                
                # Get best match in this collection
                max_idx = np.argmax(similarities)
                max_similarity = similarities[max_idx]
                collection_scores[collection_name] = float(max_similarity)
                
                # Update global best
                if max_similarity > best_score:
                    best_score = max_similarity
                    best_collection = collection_name
                    best_example = questions[max_idx]['text']
                    best_source = questions[max_idx]['source']
            
            logger.info(f"üéØ Query: '{query[:50]}...' -> Best match: {best_collection} ({best_score:.3f})")
            if best_example:
                logger.info(f"üìù Matched example: '{best_example[:80]}...'")
            
            # Determine routing decision
            if best_score >= self.high_confidence_threshold:
                # High confidence - route immediately
                return {
                    'status': 'routed',
                    'target_collection': best_collection,
                    'confidence': best_score,
                    'all_scores': collection_scores,
                    'display_name': self.collection_mappings.get(best_collection, {}).get('display_name'),
                    'clarification_needed': False,
                    'matched_example': best_example,
                    'source_procedure': best_source
                }
            
            elif best_score >= self.similarity_threshold:
                # Medium confidence - route but note
                return {
                    'status': 'routed',
                    'target_collection': best_collection,
                    'confidence': best_score,
                    'all_scores': collection_scores,
                    'display_name': self.collection_mappings.get(best_collection, {}).get('display_name'),
                    'clarification_needed': False,
                    'matched_example': best_example,
                    'source_procedure': best_source
                }
            
            else:
                # Low similarity - needs clarification
                return {
                    'status': 'ambiguous',
                    'target_collection': None,
                    'confidence': best_score,
                    'all_scores': collection_scores,
                    'display_name': None,
                    'clarification_needed': True,
                    'matched_example': best_example,
                    'source_procedure': best_source
                }
                
        except Exception as e:
            logger.error(f"‚ùå Error in enhanced query routing: {e}")
            return {
                'status': 'no_match',
                'target_collection': None,
                'confidence': 0.0,
                'all_scores': {},
                'display_name': None,
                'clarification_needed': True,
                'matched_example': None,
                'source_procedure': None
            }
    
    def get_collection_info(self) -> Dict[str, Any]:
        """Tr·∫£ v·ªÅ th√¥ng tin v·ªÅ t·∫•t c·∫£ collections"""
        return {
            'total_collections': len(self.collection_mappings),
            'collections': self.collection_mappings,
            'total_questions': sum(info['total_questions'] for info in self.collection_mappings.values())
        }
    
    def get_example_questions_for_collection(self, collection_name: str) -> List[Dict[str, Any]]:
        """Tr·∫£ v·ªÅ t·∫•t c·∫£ example questions cho m·ªôt collection"""
        return self.example_questions.get(collection_name, [])

class RouterBasedAmbiguousQueryService:
    """Service x·ª≠ l√Ω c√¢u h·ªèi m∆° h·ªì d·ª±a tr√™n router results"""
    
    def __init__(self, router: EnhancedSmartQueryRouter):
        self.router = router
        self.clarification_templates = {
            'ambiguous': [
                "C√¢u h·ªèi c·ªßa b·∫°n c√≥ th·ªÉ li√™n quan ƒë·∫øn nhi·ªÅu lƒ©nh v·ª±c. B·∫°n c√≥ th·ªÉ cung c·∫•p th√™m th√¥ng tin c·ª• th·ªÉ kh√¥ng?",
                "ƒê·ªÉ h·ªó tr·ª£ b·∫°n t·ªët h∆°n, b·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n v·ªÅ v·∫•n ƒë·ªÅ b·∫°n quan t√¢m?",
                "C√¢u h·ªèi c·ªßa b·∫°n kh√° chung. B·∫°n c√≥ th·ªÉ ch·ªâ r√µ b·∫°n mu·ªën t√¨m hi·ªÉu v·ªÅ th·ªß t·ª•c n√†o c·ª• th·ªÉ?"
            ],
            'no_match': [
                "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin ph√π h·ª£p v·ªõi c√¢u h·ªèi c·ªßa b·∫°n trong c∆° s·ªü d·ªØ li·ªáu hi·ªán t·∫°i.",
                "C√¢u h·ªèi n√†y c√≥ v·∫ª n·∫±m ngo√†i ph·∫°m vi h·ªó tr·ª£ c·ªßa t√¥i. B·∫°n c√≥ th·ªÉ h·ªèi v·ªÅ c√°c th·ªß t·ª•c h√†nh ch√≠nh kh√°c kh√¥ng?",
                "T√¥i kh√¥ng c√≥ th√¥ng tin v·ªÅ v·∫•n ƒë·ªÅ n√†y. B·∫°n c√≥ th·ªÉ tham kh·∫£o tr·ª±c ti·∫øp t·∫°i c∆° quan c√≥ th·∫©m quy·ªÅn."
            ]
        }
        
        logger.info("‚úÖ Router-based Ambiguous Query Service initialized")
    
    def is_ambiguous(self, query: str) -> Tuple[bool, Dict[str, Any]]:
        """
        Ki·ªÉm tra query c√≥ ambiguous kh√¥ng d·ª±a tr√™n router results
        
        Returns:
            (is_ambiguous, routing_result)
        """
        try:
            routing_result = self.router.route_query(query)
            
            is_ambiguous = routing_result['status'] in ['ambiguous', 'no_match']
            
            if is_ambiguous:
                logger.info(f"ü§î Ambiguous query detected: {query[:50]}... (confidence: {routing_result['confidence']:.3f})")
            
            return is_ambiguous, routing_result
            
        except Exception as e:
            logger.error(f"‚ùå Error checking ambiguous query: {e}")
            return True, {'status': 'error', 'confidence': 0.0}
    
    def generate_clarification_response(self, routing_result: Dict[str, Any]) -> str:
        """Generate clarification response d·ª±a tr√™n routing result"""
        try:
            status = routing_result.get('status', 'no_match')
            
            if status == 'ambiguous':
                # C√≥ match nh∆∞ng confidence th·∫•p
                templates = self.clarification_templates['ambiguous']
                base_response = templates[0]
                
                # Suggest top collections
                all_scores = routing_result.get('all_scores', {})
                if all_scores:
                    top_collections = sorted(all_scores.items(), key=lambda x: x[1], reverse=True)[:2]
                    suggestions = []
                    for collection, score in top_collections:
                        display_name = self.router.collection_mappings.get(collection, {}).get('display_name', collection)
                        suggestions.append(display_name)
                    
                    if suggestions:
                        base_response += f" C√°c lƒ©nh v·ª±c c√≥ th·ªÉ li√™n quan: {', '.join(suggestions)}."
                
                return base_response
            
            else:  # no_match
                return self.clarification_templates['no_match'][0]
                
        except Exception as e:
            logger.error(f"‚ùå Error generating clarification response: {e}")
            return "Xin l·ªói, c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω c√¢u h·ªèi c·ªßa b·∫°n."
