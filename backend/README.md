# VRAM-Optimized LegalRAG Backend

## ğŸ¯ Kiáº¿n trÃºc VRAM-Optimized

Há»‡ thá»‘ng RAG tá»‘i Æ°u hÃ³a VRAM vá»›i phÃ¢n bá»• thÃ´ng minh giá»¯a CPU vÃ  GPU:

```
Embedding Model (CPU) â†’ Broad Search â†’ Reranker (GPU) â†’ Context Expansion â†’ LLM (GPU)
```

### ğŸ—ï¸ PhÃ¢n bá»• tÃ i nguyÃªn:

- **Embedding Model**: CPU (tiáº¿t kiá»‡m VRAM, xá»­ lÃ½ query ngáº¯n)
- **LLM (PhoGPT-4B)**: GPU (song song hÃ³a, context dÃ i)
- **Reranker**: GPU (so sÃ¡nh chÃ©o nhiá»u chunks)

### ğŸ§  TÃ­nh nÄƒng thÃ´ng minh:

1. **Ambiguous Query Detection** - PhÃ¡t hiá»‡n cÃ¢u há»i mÆ¡ há»“ tá»± Ä‘á»™ng
2. **Nucleus Context Expansion** - Má»Ÿ rá»™ng ngá»¯ cáº£nh tá»« chunk háº¡t nhÃ¢n
3. **Session Management** - Quáº£n lÃ½ há»™i thoáº¡i thÃ´ng minh
4. **VRAM Optimization** - Sá»­ dá»¥ng tá»‘i Æ°u bá»™ nhá»› GPU

## ğŸ“ Cáº¥u trÃºc Project

```
backend/
â”œâ”€â”€ main.py                          # ğŸš€ Entry point chÃ­nh
â”œâ”€â”€ summary_test.py                   # ğŸ§ª Test suite chÃ­nh
â”œâ”€â”€ .env                             # âš™ï¸ Cáº¥u hÃ¬nh
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ optimized_routes.py      # ğŸŒ API v2 endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ optimized_enhanced_rag_service.py  # ğŸ¯ Service chÃ­nh
â”‚   â”‚   â”œâ”€â”€ ambiguous_query_service.py         # ğŸ§  Xá»­ lÃ½ cÃ¢u há»i mÆ¡ há»“
â”‚   â”‚   â”œâ”€â”€ enhanced_context_expansion_service.py # ğŸ“– Má»Ÿ rá»™ng ngá»¯ cáº£nh
â”‚   â”‚   â”œâ”€â”€ vectordb_service.py      # ğŸ’¾ Vector DB (CPU embedding)
â”‚   â”‚   â”œâ”€â”€ llm_service.py          # ğŸ¤– LLM (GPU)
â”‚   â”‚   â””â”€â”€ reranker_service.py     # ğŸ¯ Reranker (GPU)
â”‚   â””â”€â”€ core/
â”‚       â””â”€â”€ config.py               # âš™ï¸ Configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ documents/                  # ğŸ“„ Source documents
â”‚   â”œâ”€â”€ vectordb/                   # ğŸ’¾ ChromaDB
â”‚   â””â”€â”€ models/                     # ğŸ¤– AI models
â””â”€â”€ archive/                        # ğŸ“¦ Old files
```

## ğŸš€ Quick Start

### 1. Khá»Ÿi cháº¡y server:

```bash
conda activate LegalRAG_v1
cd backend
python main.py
```

### 2. Test há»‡ thá»‘ng:

```bash
python summary_test.py
```

### 3. API Endpoints:

- **Health Check**: `GET /api/v2/health`
- **Query**: `POST /api/v2/optimized-query`
- **Session Create**: `POST /api/v2/session/create`
- **Session Info**: `GET /api/v2/session/{session_id}`
- **Clarification**: `POST /api/v2/clarify`
- **Documentation**: `GET /docs`

## ğŸ“Š API Response Example

### Ambiguous Query Detection:

```json
{
  "type": "clarification_needed",
  "category": "general_procedure",
  "confidence": 1.0,
  "clarification": {
    "template": "Báº¡n muá»‘n há»i vá» thá»§ tá»¥c gÃ¬ cá»¥ thá»ƒ?",
    "options": ["Thá»§ tá»¥c A", "Thá»§ tá»¥c B", ...]
  },
  "generated_questions": ["CÃ¢u há»i lÃ m rÃµ 1", "CÃ¢u há»i lÃ m rÃµ 2", ...],
  "session_id": "uuid",
  "processing_time": 0.15
}
```

### Clear Query Response:

```json
{
  "type": "answer",
  "answer": "Detailed answer based on documents...",
  "context_info": {
    "nucleus_chunks": 5,
    "context_length": 2847,
    "source_collections": ["ho_tich_cap_xa"],
    "source_documents": ["document1.pdf", "document2.pdf"]
  },
  "session_id": "uuid",
  "processing_time": 2.34
}
```

## ğŸ”§ Core Services

### OptimizedEnhancedRAGService

**Vá»‹ trÃ­**: `app/services/optimized_enhanced_rag_service.py`

- VRAM-optimized architecture
- Ambiguous query detection
- Nucleus context expansion
- Session management

### Supporting Services:

- `VectorDBService` - ChromaDB vá»›i embedding CPU
- `LLMService` - PhoGPT-4B trÃªn GPU
- `RerankerService` - Vietnamese Reranker trÃªn GPU
- `AmbiguousQueryService` - PhÃ¡t hiá»‡n cÃ¢u há»i mÆ¡ há»“
- `EnhancedContextExpansionService` - Má»Ÿ rá»™ng ngá»¯ cáº£nh

## ğŸ›ï¸ Configuration

Key environment variables in `.env`:

```bash
# VRAM Optimization
EMBEDDING_MODEL_NAME=AITeamVN/Vietnamese_Embedding_v2
RERANKER_MODEL_NAME=AITeamVN/Vietnamese_Reranker
LLM_MODEL_PATH=data/models/llm_dir/PhoGPT-4B-Chat-Q4_K_M.gguf

# Performance Settings
MAX_TOKENS=1024
TEMPERATURE=0.2
CONTEXT_LENGTH=4096
BROAD_SEARCH_K=15
SIMILARITY_THRESHOLD=0.35

# Features
USE_ROUTING=true
USE_RERANKER=true
```

## ğŸ“ˆ Performance Metrics

- **VRAM Usage**: ~4-5GB (optimized from ~7-8GB)
- **Query Processing**: ~0.15s (ambiguous detection)
- **Answer Generation**: ~2-3s (with context expansion)
- **Collections**: 3 collections, 262 documents
- **Accuracy**: High precision vá»›i reranker + context expansion

## ğŸ§ª Testing

```bash
# Full system test
python summary_test.py

# Manual API test
curl -X POST "http://localhost:8000/api/v2/optimized-query" \
  -H "Content-Type: application/json" \
  -d '{"query": "thá»§ tá»¥c nhÆ° tháº¿ nÃ o"}'
```

## ğŸ“š Documentation

- **API Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/api/v2/health

---

ğŸ”¥ **VRAM-Optimized LegalRAG** - Intelligent legal Q&A system with optimized resource allocation

## Troubleshooting

### Model download fails

```bash
# Download thá»§ cÃ´ng
mkdir -p data/models
wget -O data/models/PhoGPT-4B-Chat-q8_0.gguf \
  https://huggingface.co/nguyenviet/PhoGPT-4B-Chat-GGUF/resolve/main/PhoGPT-4B-Chat-q8_0.gguf
```

### Memory issues

- Giáº£m `n_ctx` trong config
- TÄƒng swap space
- Sá»­ dá»¥ng model nhá» hÆ¡n

### Performance tuning

- TÄƒng `n_threads` theo sá»‘ CPU cores
- Äiá»u chá»‰nh `chunk_size` vÃ  `top_k`
- Sá»­ dá»¥ng SSD cho vector database

## API Documentation

Khi server Ä‘ang cháº¡y, truy cáº­p:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
