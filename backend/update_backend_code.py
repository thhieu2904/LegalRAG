#!/usr/bin/env python3
"""
üîß BACKEND CODE UPDATE FOR NEW QUESTIONS.JSON STRUCTURE

Updates backend code ƒë·ªÉ support new clean questions.json format:
‚úÖ Update router_crud.py to read questions.json + document.json
‚úÖ Add FilterEngine ƒë·ªÉ derive business logic t·ª´ metadata  
‚úÖ Maintain backward compatibility during transition
‚úÖ Add comprehensive testing
"""

import os
import json
import glob

def update_router_crud():
    """Update router_crud.py ƒë·ªÉ support new structure"""
    
    router_crud_path = "d:/Personal/LegalRAG_Fixed/backend/app/api/router_crud.py"
    
    if not os.path.exists(router_crud_path):
        print(f"‚ùå router_crud.py not found at {router_crud_path}")
        return False
    
    print("üîß UPDATING router_crud.py...")
    
    # Read current file
    with open(router_crud_path, 'r', encoding='utf-8') as f:
        current_content = f.read()
    
    # Add new imports at top
    new_imports = '''import os
from pathlib import Path
from typing import Dict, List, Any, Optional
import json
import glob
from ..services.filter_engine import FilterEngine  # New service
'''
    
    # Add new method for reading questions.json + document.json
    new_method = '''
def get_document_questions_v2(collection_name: str, document_id: str) -> Dict[str, Any]:
    """
    NEW METHOD: Load questions from questions.json + metadata t·ª´ document.json
    Replaces old router_questions.json god object approach
    """
    try:
        # Path to document directory
        doc_dir = f"data/storage/collections/{collection_name}/documents/{document_id}/"
        
        # Load questions (clean structure)
        questions_path = os.path.join(doc_dir, "questions.json")
        questions_data = {}
        
        if os.path.exists(questions_path):
            with open(questions_path, 'r', encoding='utf-8') as f:
                questions_data = json.load(f)
        else:
            # Fallback to old router_questions.json n·∫øu questions.json ch∆∞a c√≥
            router_path = os.path.join(doc_dir, "router_questions.json")
            if os.path.exists(router_path):
                with open(router_path, 'r', encoding='utf-8') as f:
                    router_data = json.load(f)
                questions_data = {
                    "main_question": router_data.get("main_question", ""),
                    "question_variants": router_data.get("question_variants", [])
                }
        
        # Load metadata t·ª´ document.json (single source of truth)
        doc_files = [f for f in os.listdir(doc_dir) 
                    if f.endswith('.json') and f not in ['questions.json', 'router_questions.json']]
        
        metadata = {}
        content_chunks = []
        
        if doc_files:
            doc_path = os.path.join(doc_dir, doc_files[0])
            with open(doc_path, 'r', encoding='utf-8') as f:
                doc_data = json.load(f)
                metadata = doc_data.get('metadata', {})
                content_chunks = doc_data.get('content_chunks', [])
        
        # Derive smart filters t·ª´ metadata (business logic in code)
        smart_filters = FilterEngine.derive_smart_filters(metadata)
        
        # Build response trong format m√† frontend expects
        response = {
            "document_id": document_id,
            "collection_name": collection_name,
            "main_question": questions_data.get("main_question", ""),
            "question_variants": questions_data.get("question_variants", []),
            "metadata": metadata,
            "smart_filters": smart_filters,
            "content_preview": content_chunks[:2] if content_chunks else [],
            "source": "questions.json + document.json"  # For debugging
        }
        
        return response
        
    except Exception as e:
        print(f"Error loading document questions v2: {e}")
        return {}

def get_questions_in_document_updated(collection_name: str, document_id: str):
    """
    UPDATED METHOD: Uses new v2 approach v·ªõi fallback to old method
    """
    # Try new approach first
    result = get_document_questions_v2(collection_name, document_id)
    
    if result:
        return result
    
    # Fallback to original method n·∫øu c√≥ l·ªói
    print(f"Falling back to original method for {document_id}")
    return get_questions_in_document_original(collection_name, document_id)

# Backup original method
def get_questions_in_document_original(collection_name: str, document_id: str):
    """Original method - kept for fallback during transition"""
    # [Keep existing implementation as backup]
    pass
'''
    
    # Check if file already has these updates
    if "get_document_questions_v2" in current_content:
        print("   ‚ö†Ô∏è  router_crud.py already contains v2 methods")
        return True
    
    # Add new method to file (append at end)
    updated_content = current_content + new_method
    
    # Write updated file
    backup_path = router_crud_path + ".backup"
    with open(backup_path, 'w', encoding='utf-8') as f:
        f.write(current_content)
    
    with open(router_crud_path, 'w', encoding='utf-8') as f:
        f.write(updated_content)
    
    print(f"   ‚úÖ router_crud.py updated")
    print(f"   üíæ Backup saved: {backup_path}")
    
    return True

def create_filter_engine():
    """Create new FilterEngine service ƒë·ªÉ handle business logic"""
    
    services_dir = "d:/Personal/LegalRAG_Fixed/backend/app/services"
    filter_engine_path = os.path.join(services_dir, "filter_engine.py")
    
    if os.path.exists(filter_engine_path):
        print("   ‚ö†Ô∏è  FilterEngine already exists")
        return True
    
    print("üîß CREATING FilterEngine service...")
    
    os.makedirs(services_dir, exist_ok=True)
    
    filter_engine_code = '''"""
FilterEngine Service - Business Logic Separation

Derives smart filters v√† business rules t·ª´ document metadata
instead of hardcoding trong JSON files (god object elimination)
"""

from typing import Dict, List, Any, Optional
import re

class FilterEngine:
    """
    Centralized business logic ƒë·ªÉ derive filters t·ª´ metadata
    Eliminates need to store business logic trong JSON files
    """
    
    @staticmethod
    def derive_smart_filters(metadata: Dict[str, Any]) -> Dict[str, Any]:
        """
        Derive comprehensive smart filters t·ª´ document metadata
        
        Args:
            metadata: Document metadata t·ª´ document.json
            
        Returns:
            Dict containing derived smart filters
        """
        if not metadata:
            return {}
        
        filters = {
            "exact_title": FilterEngine._get_exact_title_filters(metadata),
            "procedure_code": FilterEngine._get_procedure_code_filters(metadata),
            "agency": FilterEngine._get_agency_filters(metadata),
            "cost_range": FilterEngine._get_cost_range(metadata),
            "processing_category": FilterEngine._get_processing_category(metadata),
            "subject_matter": FilterEngine._get_subject_matter(metadata),
            "urgency_level": FilterEngine._get_urgency_level(metadata)
        }
        
        # Remove empty filters
        return {k: v for k, v in filters.items() if v}
    
    @staticmethod
    def _get_exact_title_filters(metadata: Dict[str, Any]) -> List[str]:
        """Extract title-based filters"""
        title = metadata.get("title", "")
        if not title:
            return []
        
        filters = [title]
        
        # Add variations
        if "ƒëƒÉng k√Ω" in title.lower():
            filters.append("th·ªß t·ª•c ƒëƒÉng k√Ω")
        if "c·∫•p" in title.lower():
            filters.append("th·ªß t·ª•c c·∫•p gi·∫•y t·ªù")
        if "ch·ª©ng th·ª±c" in title.lower():
            filters.append("ch·ª©ng th·ª±c h·ªì s∆°")
            
        return filters
    
    @staticmethod
    def _get_procedure_code_filters(metadata: Dict[str, Any]) -> List[str]:
        """Extract procedure code filters"""
        code = metadata.get("code", "")
        if not code:
            return []
        
        filters = [code]
        
        # Extract pattern-based codes
        if "QT" in code:
            filters.append("quy tr√¨nh c·∫•p x√£")
        if "CX" in code:
            filters.append("c·∫•p x√£")
        if "HCTP" in code:
            filters.append("h·ªô t·ªãch")
            
        return filters
    
    @staticmethod  
    def _get_agency_filters(metadata: Dict[str, Any]) -> List[str]:
        """Extract executing agency filters"""
        agency = metadata.get("executing_agency", "")
        if not agency:
            return []
        
        filters = [agency]
        
        # Normalize agency names
        if "c·∫•p x√£" in agency.lower():
            filters.extend(["UBND x√£", "·ªßy ban x√£", "ch√≠nh quy·ªÅn c∆° s·ªü"])
        if "c·∫•p huy·ªán" in agency.lower():
            filters.extend(["UBND huy·ªán", "·ªßy ban huy·ªán"])
        if "c·∫•p t·ªânh" in agency.lower():
            filters.extend(["UBND t·ªânh", "·ªßy ban t·ªânh"])
            
        return filters
    
    @staticmethod
    def _get_cost_range(metadata: Dict[str, Any]) -> str:
        """Determine cost category"""
        fee = metadata.get("fee_vnd")
        
        if fee is None or fee == 0:
            return "free"
        elif fee < 50000:
            return "very_low"
        elif fee < 100000:
            return "low"
        elif fee < 300000:
            return "medium"
        elif fee < 500000:
            return "high"
        else:
            return "very_high"
    
    @staticmethod
    def _get_processing_category(metadata: Dict[str, Any]) -> str:
        """Determine processing time category"""
        processing_time = metadata.get("processing_time", "")
        
        if not processing_time:
            return "unknown"
        
        # Extract s·ªë ng√†y
        if "ng√†y" in processing_time.lower():
            try:
                days = int(re.search(r'(\d+)', processing_time).group(1))
                if days <= 1:
                    return "instant"
                elif days <= 3:
                    return "fast"  
                elif days <= 7:
                    return "normal"
                elif days <= 15:
                    return "slow"
                else:
                    return "very_slow"
            except:
                pass
        
        if "t·ª©c th√¨" in processing_time.lower():
            return "instant"
        if "nhanh" in processing_time.lower():
            return "fast"
            
        return "normal"
    
    @staticmethod
    def _get_subject_matter(metadata: Dict[str, Any]) -> List[str]:
        """Extract thematic subject matter"""
        title = metadata.get("title", "").lower()
        subjects = []
        
        # Thematic categorization
        if any(word in title for word in ["khai sinh", "h·ªô t·ªãch", "sinh"]):
            subjects.append("birth_registration")
        if any(word in title for word in ["k·∫øt h√¥n", "h√¥n nh√¢n"]):
            subjects.append("marriage")
        if any(word in title for word in ["ch·ª©ng th·ª±c", "c√¥ng ch·ª©ng"]):
            subjects.append("notarization")
        if any(word in title for word in ["gi·∫•y ph√©p", "c·∫•p ph√©p"]):
            subjects.append("licensing")
        if any(word in title for word in ["thu·∫ø", "t√†i ch√≠nh"]):
            subjects.append("taxation")
            
        return subjects
    
    @staticmethod
    def _get_urgency_level(metadata: Dict[str, Any]) -> str:
        """Determine urgency based on processing time v√† cost"""
        processing_time = metadata.get("processing_time", "")
        fee = metadata.get("fee_vnd", 0)
        
        # Instant procedures = high urgency
        if "t·ª©c th√¨" in processing_time.lower():
            return "high"
        
        # Free procedures = often urgent public services    
        if fee == 0:
            return "medium"
        
        # Quick + low cost = standard urgency
        if "ng√†y" in processing_time.lower():
            try:
                days = int(re.search(r'(\d+)', processing_time).group(1))
                if days <= 3:
                    return "medium"
                elif days > 10:
                    return "low"
            except:
                pass
                
        return "normal"
    
    @staticmethod
    def get_collection_mapping(metadata: Dict[str, Any]) -> str:
        """
        Determine appropriate collection based on metadata
        Replaces hardcoded expected_collection trong router_questions.json
        """
        title = metadata.get("title", "").lower()
        agency = metadata.get("executing_agency", "").lower()
        
        # Collection mapping logic
        if "h·ªô t·ªãch" in title or "khai sinh" in title:
            return "quy_trinh_cap_ho_tich_cap_xa"
        elif "ch·ª©ng th·ª±c" in title or "c√¥ng ch·ª©ng" in title:
            return "quy_trinh_chung_thuc"
        elif "c·∫•p x√£" in agency:
            return "quy_trinh_cap_xa_tong_hop"
        elif "c·∫•p huy·ªán" in agency:
            return "quy_trinh_cap_huyen"
        else:
            return "quy_trinh_tong_hop"
'''

    with open(filter_engine_path, 'w', encoding='utf-8') as f:
        f.write(filter_engine_code)
    
    print(f"   ‚úÖ FilterEngine created: {filter_engine_path}")
    return True

def create_backend_integration_test():
    """Create test script ƒë·ªÉ validate backend integration"""
    
    test_script = '''#!/usr/bin/env python3
"""
üß™ BACKEND INTEGRATION TEST

Tests new questions.json + document.json architecture v·ªõi backend
"""

import requests
import json
import sys
import os

# Add parent directory to path ƒë·ªÉ import backend modules
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

def test_backend_integration():
    """Test backend APIs v·ªõi new structure"""
    
    print("üß™ BACKEND INTEGRATION TEST")
    print("=" * 50)
    
    # Test data
    test_cases = [
        {
            "collection": "quy_trinh_cap_ho_tich_cap_xa",
            "document": "DOC_001",
            "expected_question": "khai sinh"
        },
        {
            "collection": "quy_trinh_chung_thuc", 
            "document": "DOC_001",
            "expected_question": "ch·ª©ng th·ª±c"
        }
    ]
    
    passed_tests = 0
    total_tests = len(test_cases)
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\\nüìã Test {i}: {test_case['collection']}/{test_case['document']}")
        
        try:
            # Test API endpoint (adjust URL as needed)
            url = f"http://localhost:8000/api/questions/{test_case['collection']}/{test_case['document']}"
            response = requests.get(url, timeout=5)
            
            if response.status_code == 200:
                data = response.json()
                
                # Validate response structure
                required_fields = ["main_question", "question_variants", "metadata", "smart_filters"]
                has_all_fields = all(field in data for field in required_fields)
                
                if has_all_fields:
                    print(f"   ‚úÖ API Response OK")
                    print(f"   üìä Fields: {list(data.keys())}")
                    print(f"   üéØ Main Question: {data['main_question'][:50]}...")
                    print(f"   üìù Variants Count: {len(data.get('question_variants', []))}")
                    print(f"   üîß Smart Filters: {list(data.get('smart_filters', {}).keys())}")
                    
                    passed_tests += 1
                else:
                    print(f"   ‚ùå Missing required fields")
                    print(f"      Expected: {required_fields}")
                    print(f"      Found: {list(data.keys())}")
            else:
                print(f"   ‚ùå API Error: {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            print(f"   ‚ö†Ô∏è  Backend not running - Start backend first")
        except Exception as e:
            print(f"   ‚ùå Test Error: {e}")
    
    print(f"\\n" + "=" * 50)
    print(f"üéØ TEST RESULTS:")
    print(f"   Passed: {passed_tests}/{total_tests}")
    print(f"   Success Rate: {(passed_tests/total_tests)*100:.1f}%")
    
    if passed_tests == total_tests:
        print("   ‚úÖ ALL TESTS PASSED")
        return True
    else:
        print("   ‚ö†Ô∏è  SOME TESTS FAILED")
        return False

def test_file_structure():
    """Test file structure integrity"""
    
    print("\\nüìÅ TESTING FILE STRUCTURE...")
    
    # Check questions.json files
    questions_files = glob.glob("data/**/*questions.json", recursive=True)
    print(f"   Found {len(questions_files)} questions.json files")
    
    # Validate sample file
    if questions_files:
        sample_file = questions_files[0]
        with open(sample_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if "main_question" in data and "question_variants" in data:
            print(f"   ‚úÖ File structure valid")
            return True
        else:
            print(f"   ‚ùå Invalid file structure")
            return False
    else:
        print(f"   ‚ùå No questions.json files found")
        return False

if __name__ == "__main__":
    print("üöÄ STARTING BACKEND INTEGRATION TESTS")
    print("Make sure backend is running on localhost:8000")
    print()
    
    # Test file structure first
    file_test_passed = test_file_structure()
    
    if file_test_passed:
        # Test backend integration
        api_test_passed = test_backend_integration()
        
        if api_test_passed:
            print("\\nüéâ ALL INTEGRATION TESTS PASSED!")
        else:
            print("\\n‚ö†Ô∏è  INTEGRATION TESTS NEED ATTENTION")
    else:
        print("\\n‚ùå FILE STRUCTURE TESTS FAILED")
'''

    test_path = "d:/Personal/LegalRAG_Fixed/backend/test_backend_integration.py"
    with open(test_path, 'w', encoding='utf-8') as f:
        f.write(test_script)
    
    print(f"‚úÖ Integration test created: {test_path}")
    return test_path

if __name__ == "__main__":
    print("üîß BACKEND CODE UPDATE FOR NEW ARCHITECTURE")
    print("=" * 60)
    
    # Step 1: Create FilterEngine service
    filter_success = create_filter_engine()
    
    # Step 2: Update router_crud.py
    crud_success = update_router_crud()
    
    # Step 3: Create integration test
    test_path = create_backend_integration_test()
    
    print("\\n" + "=" * 60)
    print("üéØ BACKEND UPDATE SUMMARY:")
    print(f"   FilterEngine: {'‚úÖ' if filter_success else '‚ùå'}")
    print(f"   router_crud.py: {'‚úÖ' if crud_success else '‚ùå'}")
    print(f"   Integration Test: ‚úÖ")
    
    print(f"\\nüöÄ NEXT STEPS:")
    print(f"   1. Start backend server")
    print(f"   2. Run: python {os.path.basename(test_path)}")
    print(f"   3. Verify API responses")
    print(f"   4. Test frontend integration")
