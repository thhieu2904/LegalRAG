#!/usr/bin/env python3
"""
üß™ Performance Fix Verification Test
Test reranker GPU usage and document count optimization
"""

import asyncio
import aiohttp
import json
import time
from datetime import datetime

print("üö® NH·∫ÆC NH·ªû: B·∫°n c·∫ßn RESTART backend sau khi apply fixes!")
print("   cd backend && python main.py")
print("=" * 60)

async def test_performance_fixes():
    """Test performance improvements sau khi apply fixes"""
    base_url = "http://localhost:8000"
    
    print("üîß TESTING PERFORMANCE FIXES")
    print("=" * 60)
    
    async with aiohttp.ClientSession() as session:
        
        # Test query v·ªõi timing measurement
        test_queries = [
            {
                "query": "Th·ªß t·ª•c ƒëƒÉng k√Ω khai sinh ·ªü c·∫•p x√£ c·∫ßn gi·∫•y t·ªù g√¨?",
                "expected_collection": "quy_trinh_cap_ho_tich_cap_xa",
                "expected_confidence": "high"
            }
        ]
        
        for i, test in enumerate(test_queries):
            print(f"\nüß™ TEST {i+1}: {test['query'][:50]}...")
            
            # Measure total time
            start_time = time.time()
            
            test_query = {
                "query": test['query'],
                "session_id": f"perf_test_{int(time.time())}_{i}"
            }
            
            try:
                async with session.post(f"{base_url}/api/v1/query", json=test_query) as response:
                    if response.status == 200:
                        result = await response.json()
                        end_time = time.time()
                        total_time = end_time - start_time
                        
                        print(f"‚úÖ Query completed in {total_time:.2f}s")
                        print(f"   ‚Ä¢ Response type: {result.get('response_type', 'unknown')}")
                        print(f"   ‚Ä¢ Confidence: {result.get('confidence', 'N/A')}")
                        print(f"   ‚Ä¢ Collection: {result.get('collection', 'N/A')}")
                        
                        # Performance expectations
                        if total_time < 20:
                            print(f"   ‚úÖ GOOD: Total time under 20s")
                        elif total_time < 30:
                            print(f"   ‚ö†Ô∏è  ACCEPTABLE: Total time under 30s")
                        else:
                            print(f"   ‚ùå SLOW: Total time over 30s - optimization needed")
                            
                        # Check if forms were detected
                        if 'forms' in result and result['forms']:
                            print(f"   üìé Forms detected: {len(result['forms'])}")
                            
                    else:
                        print(f"   ‚ùå Query failed: {response.status}")
                        
            except Exception as e:
                print(f"   ‚ùå Query error: {e}")
        
        # Test health to check GPU status
        print(f"\nüè• Checking system health after fixes...")
        try:
            async with session.get(f"{base_url}/health") as response:
                if response.status == 200:
                    health = await response.json()
                    print("   ‚úÖ Health check passed")
                    print(f"      ‚Ä¢ LLM loaded: {health.get('llm_loaded', 'N/A')}")
                    print(f"      ‚Ä¢ Reranker loaded: {health.get('reranker_loaded', 'N/A')}")
                    print(f"      ‚Ä¢ Collections: {health.get('total_collections', 'N/A')}")
                    print(f"      ‚Ä¢ Documents: {health.get('total_documents', 'N/A')}")
                    
                    # Check if models are properly detected
                    if health.get('llm_loaded') and health.get('reranker_loaded'):
                        print("   ‚úÖ Both LLM and Reranker are properly loaded")
                    else:
                        print("   ‚ö†Ô∏è  Model loading detection may need adjustment")
                        
        except Exception as e:
            print(f"   ‚ùå Health check failed: {e}")

async def analyze_backend_logs():
    """H∆∞·ªõng d·∫´n ph√¢n t√≠ch logs ƒë·ªÉ verify fixes"""
    print(f"\nüìä LOG ANALYSIS GUIDE")
    print("=" * 60)
    
    print("üîç Look for these IMPROVEMENTS in backend logs:")
    print()
    print("1Ô∏è‚É£ RERANKER GPU USAGE:")
    print("   BEFORE: '‚úÖ Reranker model loaded from local cache on CPU'")
    print("   AFTER:  '‚úÖ Reranker model loaded from local cache on GPU'")
    print("   BEFORE: 'RERANK COMPLETED in 49.31s'")
    print("   AFTER:  'RERANK COMPLETED in 3-5s'")
    print()
    print("2Ô∏è‚É£ DOCUMENT COUNT REDUCTION:")
    print("   BEFORE: 'üéØ HIGH CONFIDENCE: Gi·∫£m broad_search_k xu·ªëng 16'")
    print("   AFTER:  'üéØ HIGH CONFIDENCE: Aggressive reduction to 6 docs'")
    print("   BEFORE: 'Found 26 candidate chunks'")
    print("   AFTER:  'Found 6-8 candidate chunks'")
    print()
    print("3Ô∏è‚É£ TOTAL PERFORMANCE:")
    print("   BEFORE: Total query time ~65s")
    print("   AFTER:  Total query time ~15s")
    print()
    print("‚ö†Ô∏è  NOTE: You need to RESTART backend to see these changes!")

if __name__ == "__main__":
    import sys
    
    print("üéØ PERFORMANCE FIX VERIFICATION")
    print("=" * 60)
    print("‚úÖ Applied fixes:")
    print("   1. Reranker GPU device detection")
    print("   2. Reduced broad_search_k: 20 ‚Üí 12")
    print("   3. Aggressive high confidence: 16 ‚Üí 6 docs")
    print()
    
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        asyncio.run(test_performance_fixes())
    else:
        asyncio.run(analyze_backend_logs())
        print("\nüß™ To run live performance test:")
        print("   python test_performance_fixes.py test")
