#!/usr/bin/env python3
"""
TEST: Hybrid Format Fix - Ki·ªÉm tra format ƒë∆°n gi·∫£n h∆°n v·ªõi PhoGPT
"""

import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), 'backend'))

from app.services.language_model import LLMService

def test_hybrid_format():
    """Test hybrid format - format ƒë∆°n gi·∫£n h∆°n cho PhoGPT"""
    
    print("=== TEST HYBRID FORMAT FIX ===")
    
    # Initialize service
    llm_service = LLMService()
    
    # Test query
    query = "Th·ªß t·ª•c ƒëƒÉng k√Ω k·∫øt h√¥n c√≥ t√≠nh ph√≠ kh√¥ng?"
    context = "Th√¥ng tin ƒëƒÉng k√Ω k·∫øt h√¥n mi·ªÖn ph√≠."
    
    print(f"üîç Query: {query}")
    print(f"üìÑ Context: {context}")
    
    try:
        # Generate response
        result = llm_service.generate_response(
            user_query=query,
            context=context
        )
        
        print(f"\n‚úÖ Success!")
        print(f"üìù Response: '{result['response']}'")
        print(f"üìä Response length: {len(result['response'])} chars")
        print(f"‚è±Ô∏è Processing time: {result['processing_time']:.2f}s")
        print(f"üßÆ Tokens - Prompt: {result['prompt_tokens']}, Completion: {result['completion_tokens']}")
        
        # Check if response is meaningful
        if len(result['response']) > 20 and "mi·ªÖn ph√≠" in result['response'].lower():
            print("‚úÖ RESPONSE LOOKS GOOD!")
        else:
            print("‚ùå Response still needs improvement")
            
    except Exception as e:
        print(f"‚ùå Error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_hybrid_format()
